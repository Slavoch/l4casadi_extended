{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.253967\n",
      "0.753405\n"
     ]
    }
   ],
   "source": [
    "import casadi as cs\n",
    "import torch\n",
    "import l4casadi as l4c\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Cs_Torch(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def check_cs_torch_consistancy(self, N_iter=2):\n",
    "        cs_input_params = [cs.MX.sym('x', 2, 1)]\n",
    "        for param in self.parameters():\n",
    "            cs_input_params.append(cs.MX.sym('x', param.flatten().shape[0], 1))\n",
    "        cs_input = cs.vcat(cs_input_params)\n",
    "        self.set_model_type(\"casadi\")\n",
    "        cs_model = l4c.L4CasADi(self, has_batch=False, device='cpu')\n",
    "        cs_model = cs.Function('f_cs', [cs_input], [cs_model(cs_input)])\n",
    "        for _ in range(N_iter):\n",
    "            random_inp = np.random.random(cs_input.shape[0])\n",
    "            print(cs_model(cs.DM(random_inp)))\n",
    "            ### TO DO complete comparison of both methods\n",
    "\n",
    "    def linear(self, in_features, out_features, bias: bool = True):\n",
    "        torch_layer = torch.nn.Linear(in_features, out_features, bias)\n",
    "        cs_layer = self.cs_linear(in_features, out_features, bias)\n",
    "\n",
    "        def linear_wrapper(input, weights=None, *args, **kwargs):\n",
    "            if (self.type == \"torch\"):\n",
    "                return torch_layer(input, args, kwargs)\n",
    "            elif (self.type == \"casadi\"):\n",
    "                return cs_layer(input, weights)\n",
    "\n",
    "        return linear_wrapper\n",
    "\n",
    "    def cs_linear(self, in_features, out_features, bias):\n",
    "\n",
    "        def wrapper(input, weights):\n",
    "            A = weights.pop()\n",
    "            if bias:\n",
    "                return input @ A.T + weights.pop()\n",
    "            else:\n",
    "                return input @ A.T\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    def pack_up_input(self, input):\n",
    "        x = input[:self.input_size]\n",
    "        weights = input[self.input_size:]\n",
    "\n",
    "        weights_package = []\n",
    "        pointer = 0\n",
    "        for param in self.parameters():\n",
    "            rows, cols = param.shape()\n",
    "            w = weights[pointer:pointer + rows * cols].reshape(rows, cols)\n",
    "            weights_package.append(w)\n",
    "            pointer = pointer + rows * cols\n",
    "        weights_package.reverse()\n",
    "        return x, weights_package\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__(input_size)\n",
    "        self.input_layer = torch.nn.Linear(2, 4, bias=False)\n",
    "        self.out_layer = torch.nn.Linear(4, 1, bias=False)\n",
    "        self.check_cs_torch_consistancy()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        if (self.type == \"torch\"):\n",
    "            x = self.input_layer(inp)\n",
    "            x = self.out_layer(x)\n",
    "            return x\n",
    "        elif (self.type == \"casadi\"):\n",
    "            x = inp[:2]\n",
    "            weight0 = inp[2:2 + 2 * 4].reshape(2, 4)\n",
    "            weight1 = inp[10:14].reshape(4, 1)\n",
    "            x = x.T @ weight0\n",
    "            x = x @ weight1\n",
    "            return x\n",
    "        else:\n",
    "            Exception(\n",
    "                \"Please specify the model return type with set_model_type method\"\n",
    "            )\n",
    "\n",
    "    def set_model_type(self, type):\n",
    "        self.type = type\n",
    "\n",
    "\n",
    "pyTorch_model = MultiLayerPerceptron(2)\n",
    "pyTorch_model.set_model_type(\"casadi\")\n",
    "l4c_model = l4c.L4CasADi(pyTorch_model, has_batch=False,\n",
    "                         device='cpu')  # device='cuda' for GPU\n",
    "\n",
    "x_sym = cs.MX.sym('x', 2, 1)\n",
    "w_sym = cs.MX.sym('x', 2, 1)\n",
    "\n",
    "inp_sym = cs.vcat([x_sym, w_sym])\n",
    "\n",
    "# f_sym = l4c_model(inp_sym)\n",
    "# f = cs.Function('y', [inp_sym], [f_sym])\n",
    "# df = cs.Function('dy', [inp_sym], [cs.jacobian(f_sym, x_sym)])\n",
    "# ddf = cs.Function('ddy', [inp_sym], [cs.hessian(f_sym, x_sym)[0]])\n",
    "\n",
    "# inp = cs.DM([[0.], [2.], [2.], [4.]])\n",
    "# print(\"l4c_model(inp)\", l4c_model(inp))\n",
    "# print(\"f(inp)\", f(inp))\n",
    "# print(\"df(inp)\", df(inp))\n",
    "# print(\"ddf(inp)\", ddf(inp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "a = [0, 1, 2, 3]\n",
    "a.reverse()\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "import torch\n",
    "from torch import nn\n",
    "import casadi as cs\n",
    "import l4casadi as l4c\n",
    "\n",
    "\n",
    "class ModelNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Class of pytorch neural network models. This class is not to be used barebones.\n",
    "    Instead, you should inherit from it and specify your concrete architecture.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model_name = \"NN\"\n",
    "\n",
    "    def __call__(self, *args, weights=None, use_stored_weights=False):\n",
    "        if use_stored_weights is False:\n",
    "            if weights is not None:\n",
    "                return self.forward(*args, weights=weights)\n",
    "            else:\n",
    "                return self.forward(*args)\n",
    "        else:\n",
    "            return self.cache.forward(*args)\n",
    "\n",
    "    @property\n",
    "    def cache(self):\n",
    "        \"\"\"\n",
    "        Isolate parameters of cached model from the current model\n",
    "        \"\"\"\n",
    "        return self.cached_model[0]\n",
    "\n",
    "    def detach_weights(self):\n",
    "        \"\"\"\n",
    "        Excludes the model's weights from the pytorch computation graph.\n",
    "        This is needed to exclude the weights from the decision variables in optimization problems.\n",
    "        An example is temporal-difference optimization, where the old critic is to be treated as a frozen model.\n",
    "\n",
    "        \"\"\"\n",
    "        for variable in self.parameters():\n",
    "            variable.detach_()\n",
    "\n",
    "    def cache_weights(self, whatever=None):\n",
    "        \"\"\"\n",
    "        Assign the active model weights to the cached model followed by a detach.\n",
    "\n",
    "        This method also backs up itself and performs this operation only once upon the initialization procedure\n",
    "        \"\"\"\n",
    "        if \"cached_model\" not in self.__dict__.keys():\n",
    "            self.cached_model = (\n",
    "                deepcopy(self),\n",
    "            )  # this is needed to prevent cached_model's parameters to be parsed by model init hooks\n",
    "\n",
    "        self.cache.load_state_dict(self.weights)\n",
    "        self.cache.detach_weights()\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self.state_dict()\n",
    "\n",
    "    def update_weights(self, whatever=None):\n",
    "        pass\n",
    "\n",
    "    def weights2dict(self, weights_to_parse):\n",
    "        \"\"\"\n",
    "        Transform weights as a numpy array into a dictionary compatible with pytorch.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        weights_to_parse = torch.tensor(weights_to_parse)\n",
    "\n",
    "        new_state_dict = {}\n",
    "\n",
    "        length_old = 0\n",
    "\n",
    "        for param_tensor in self.state_dict():\n",
    "            weights_size = self.state_dict()[param_tensor].size()\n",
    "            weights_length = math.prod(self.state_dict()[param_tensor].size())\n",
    "            new_state_dict[param_tensor] = torch.reshape(\n",
    "                weights_to_parse[length_old:length_old + weights_length],\n",
    "                tuple(weights_size),\n",
    "            )\n",
    "            length_old = weights_length\n",
    "\n",
    "        return new_state_dict\n",
    "\n",
    "    def update_and_cache_weights(self, weights=None):\n",
    "        if weights is not None:\n",
    "            for item in weights:\n",
    "                weights[item].requires_grad_()\n",
    "            weights = self.load_state_dict(weights)\n",
    "        # self.load_state_dict(self.weights2dict(weights))\n",
    "        self.cache_weights()\n",
    "\n",
    "    def restore_weights(self):\n",
    "        \"\"\"\n",
    "        Assign the weights of the cached model to the active model.\n",
    "        This may be needed when pytorch optimizer resulted in unsatisfactory weights, for instance.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.update_and_cache_weights(self.cache.state_dict())\n",
    "\n",
    "    def soft_update(self, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (Torch model): weights will be copied from\n",
    "            target_model (Torch model): weights will be copied to\n",
    "            tau (float): interpolation parameter\n",
    "\n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(self.cache.parameters(),\n",
    "                                             self.parameters()):\n",
    "            target_param.data.copy_(tau * local_param.data +\n",
    "                                    (1.0 - tau) * target_param.data)\n",
    "\n",
    "    def __call__(self, *argin, weights=None, use_stored_weights=False):\n",
    "        if len(argin) > 1:\n",
    "            argin = cs.concatenate(argin)\n",
    "        else:\n",
    "            argin = argin[0]\n",
    "\n",
    "        argin = argin if isinstance(argin,\n",
    "                                    torch.Tensor) else torch.tensor(argin)\n",
    "\n",
    "        if use_stored_weights is False:\n",
    "            if weights is not None:\n",
    "                result = self.forward(argin, weights)\n",
    "            else:\n",
    "                result = self.forward(argin)\n",
    "        else:\n",
    "            result = self.cache.forward(argin)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "class ModelPerceptron(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_input: int,\n",
    "        dim_output: int,\n",
    "        dim_hidden: int,\n",
    "        n_hidden_layers: int,\n",
    "        leaky_relu_coef: float = 0.15,\n",
    "        is_force_infinitesimal: bool = False,\n",
    "        is_bias: bool = True,\n",
    "        weights=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_input = dim_input\n",
    "        self.dim_output = dim_output\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.leaky_relu_coef = leaky_relu_coef\n",
    "        self.is_force_infinitesimal = is_force_infinitesimal\n",
    "        self.is_bias = is_bias\n",
    "\n",
    "        self.input_layer = nn.Linear(dim_input, dim_hidden,\n",
    "                                     bias=is_bias).float()\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(dim_hidden, dim_hidden, bias=is_bias).float()\n",
    "            for _ in range(n_hidden_layers)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(dim_hidden, dim_output,\n",
    "                                      bias=is_bias).float()\n",
    "\n",
    "        if weights is not None:\n",
    "            self.load_state_dict(weights)\n",
    "\n",
    "        # self.cache_weights()\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x = nn.functional.leaky_relu(self.input_layer(x),\n",
    "                                     negative_slope=self.leaky_relu_coef)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = nn.functional.leaky_relu(layer(x),\n",
    "                                         negative_slope=self.leaky_relu_coef)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input_tensor, weights=None):\n",
    "        # if weights is not None:\n",
    "        #     self.update(weights)\n",
    "        return self._forward(input_tensor) - self._forward(\n",
    "            torch.zeros_like(input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00713383\n",
      "-0.00713383\n",
      "[[-0.0304231, -0.006513]]\n",
      "\n",
      "[[0, 0], \n",
      " [0, 0]]\n"
     ]
    }
   ],
   "source": [
    "pyTorch_model = ModelPerceptron(2, 1, 16, 2)\n",
    "l4c_model = l4c.L4CasADi(pyTorch_model, has_batch=True,\n",
    "                         device='cpu')  # device='cuda' for GPU\n",
    "\n",
    "x_sym = cs.MX.sym('x', 2)\n",
    "y_sym = l4c_model(x_sym)\n",
    "f = cs.Function('y', [x_sym], [y_sym])\n",
    "df = cs.Function('dy', [x_sym], [cs.jacobian(y_sym, x_sym)])\n",
    "ddf = cs.Function('ddy', [x_sym], [cs.hessian(y_sym, x_sym)[0]])\n",
    "\n",
    "x = cs.DM([[0.], [2.]])\n",
    "print(l4c_model(x))\n",
    "print(f(x))\n",
    "print(df(x))\n",
    "print(ddf(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0197)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyTorch_model(torch.FloatTensor(np.random.random(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "import torch\n",
    "import casadi as cs\n",
    "import l4casadi as l4c\n",
    "\n",
    "\n",
    "class DeepModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layer = torch.nn.Linear(dim_in, 512)\n",
    "\n",
    "        hidden_layers = []\n",
    "        for i in range(20):\n",
    "            hidden_layers.append(torch.nn.Linear(512, 512))\n",
    "\n",
    "        self.ln = torch.nn.LayerNorm(512)\n",
    "\n",
    "        self.hidden_layer = torch.nn.ModuleList(hidden_layers)\n",
    "        self.out_layer = torch.nn.Linear(512, dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for layer in self.hidden_layer:\n",
    "            x = torch.tanh(layer(x))\n",
    "        x = self.ln(x)\n",
    "        x = self.out_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TrigModel(torch.nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.stack([torch.sin(x[:1]), torch.cos(x[1:2])], dim=-1)\n",
    "\n",
    "\n",
    "class TestL4CasADi:\n",
    "\n",
    "    @pytest.fixture(params=[(1, 3), (2, 3), (3, 1)])\n",
    "    def deep_model(self, request):\n",
    "        in_dim, out_dim = request.param\n",
    "        return DeepModel(in_dim, out_dim)\n",
    "\n",
    "    @pytest.fixture\n",
    "    def triag_model(self):\n",
    "        return TrigModel()\n",
    "\n",
    "    def test_l4casadi_deep_model(self, deep_model):\n",
    "        rand_inp = torch.rand((1, deep_model.input_layer.in_features))\n",
    "        torch_out = deep_model(rand_inp)\n",
    "\n",
    "        l4c_out = l4c.L4CasADi(deep_model, has_batch=True)(rand_inp.transpose(\n",
    "            -2, -1).detach().numpy())\n",
    "\n",
    "        np.allclose(l4c_out, torch_out.transpose(-2, -1).detach().numpy())\n",
    "\n",
    "    def test_l4casadi_triag_model(self, triag_model):\n",
    "        rand_inp = torch.rand((12, 12))\n",
    "        torch_out = triag_model(rand_inp)\n",
    "\n",
    "        l4c_out = l4c.L4CasADi(triag_model)(rand_inp.detach().numpy())\n",
    "\n",
    "        np.allclose(l4c_out, torch_out.detach().numpy())\n",
    "\n",
    "    def test_l4casadi_deep_model_jac(self, deep_model):\n",
    "        rand_inp = torch.rand((1, deep_model.input_layer.in_features))\n",
    "        torch_out = torch.func.vmap(torch.func.jacrev(deep_model))(rand_inp)[0]\n",
    "\n",
    "        mx_inp = cs.MX.sym('x', deep_model.input_layer.in_features, 1)\n",
    "\n",
    "        jac_fun = cs.Function('f_jac', [mx_inp], [\n",
    "            cs.jacobian(\n",
    "                l4c.L4CasADi(deep_model, has_batch=True)(mx_inp), mx_inp)\n",
    "        ])\n",
    "\n",
    "        l4c_out = jac_fun(rand_inp.transpose(-2, -1).detach().numpy())\n",
    "\n",
    "        np.allclose(l4c_out, torch_out.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slava/Desktop/Docker/venv/lib/python3.9/site-packages/torch/jit/_check.py:172: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    }
   ],
   "source": [
    "deep_model = DeepModel(5, 40)\n",
    "mx_inp = cs.MX.sym('x', deep_model.input_layer.in_features, 1)\n",
    "l4c.L4CasADi(deep_model, has_batch=True, name='f1')(mx_inp)\n",
    "\n",
    "deep_model = DeepModel(10, 40)\n",
    "mx_inp = cs.MX.sym('x', deep_model.input_layer.in_features, 1)\n",
    "a = l4c.L4CasADi(deep_model, has_batch=True, name='f2')(mx_inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
